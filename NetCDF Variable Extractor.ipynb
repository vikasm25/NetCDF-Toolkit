{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3633a68b",
   "metadata": {},
   "source": [
    "NetCDF variable extractor (Single File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36310566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NetCDF variable extractor (Single File)\n",
    "---------------------------------------------------\n",
    "\n",
    "❶  Point INPUT_FILE at any NetCDF file.\n",
    "❷  List one or more VARS_TO_EXTRACT.\n",
    "❸  Set OUTPUT_DIR (created automatically if absent).\n",
    "❹  Adjust parse_time_from_filename() if your date pattern differs.\n",
    "\n",
    "If the file name contains no 6-digit YYYYMM block, the script falls\n",
    "back to  <varPart>_<originalFileStem>.nc.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "\n",
    "# ========= USER CONFIGURATION ==========================================\n",
    "INPUT_FILE      = r\"Enter Input File Path\"\n",
    "VARS_TO_EXTRACT = [\"Vaiable Name\"]                                                  # e.g. \"V1\" or [\"V1\",\"V2\"]\n",
    "OUTPUT_DIR      = r\"Enter Output Directory\"\n",
    "OVERWRITE       = False                                                     # True → silently replace existing files\n",
    "# =======================================================================\n",
    "\n",
    "\n",
    "def parse_time_from_filename(file_path: Path) -> str | None:\n",
    "    \"\"\"\n",
    "    Return 'YYYY_MM' if a six-digit YYYYMM block is found in *file_path.stem*;\n",
    "    otherwise return None.\n",
    "    \"\"\"\n",
    "    stem   = file_path.stem\n",
    "    digits = ''.join(reversed([c for c in stem[::-1] if c.isdigit()][:6]))\n",
    "    if len(digits) == 6:\n",
    "        return f\"{digits[:4]}_{digits[4:]}\"                                 # \"2018_12\"\n",
    "    return None                                                             # no date found\n",
    "\n",
    "\n",
    "def extract_and_save(input_file: str,\n",
    "                     variables,\n",
    "                     output_dir: str,\n",
    "                     overwrite: bool = False) -> None:\n",
    "    \"\"\"Extract *variables* from *input_file* and save to *output_dir*.\"\"\"\n",
    "\n",
    "    fp      = Path(input_file).expanduser().resolve()\n",
    "    out_dir = Path(output_dir).expanduser().resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ds = xr.open_dataset(fp)\n",
    "\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "\n",
    "    missing = [v for v in variables if v not in ds]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Variable(s) not found in {fp.name}: {missing}\")\n",
    "\n",
    "    subset = ds[variables]\n",
    "\n",
    "    # ---------- build output filename -----------------------------------\n",
    "    tag       = parse_time_from_filename(fp)                                # None if no date\n",
    "    var_part  = \"_\".join(variables)\n",
    "\n",
    "    if tag:                                                                 # date found\n",
    "        out_name = f\"{var_part}_Conc_{tag}.nc\"\n",
    "    else:                                                                   # no date → use file stem\n",
    "        out_name = f\"{var_part}_{fp.stem}.nc\"\n",
    "\n",
    "    out_path = out_dir / out_name\n",
    "\n",
    "    if out_path.exists() and not overwrite:\n",
    "        raise FileExistsError(f\"{out_path} exists (set OVERWRITE=True).\")\n",
    "\n",
    "    subset.to_netcdf(out_path, mode=\"w\", engine=\"netcdf4\")\n",
    "    print(f\"✔  Saved {variables} → {out_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_and_save(INPUT_FILE,\n",
    "                     VARS_TO_EXTRACT,\n",
    "                     OUTPUT_DIR,\n",
    "                     overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47451505",
   "metadata": {},
   "source": [
    "NetCDF variable extractor (Multiple File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NetCDF variable extractor (Multiple File)\n",
    "==============================\n",
    "\n",
    "For every NetCDF file in INPUT_DIR:\n",
    "    • open the file\n",
    "    • pull out VARS_TO_EXTRACT\n",
    "    • write a new file to OUTPUT_DIR\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "\n",
    "# ========= USER CONFIGURATION ==========================================\n",
    "INPUT_DIR        = r\"Enter Input File Directory\"                             # where the original files live\n",
    "OUTPUT_DIR       = r\"Enter Output File Directory\"                            # where you want the extracted files\n",
    "VARS_TO_EXTRACT  = [\"Vaiable Name\"]                                          # e.g. \"V1\" or [\"V1\",\"V2\"]\n",
    "OVERWRITE        = True                                                      # True → silently replace existing output\n",
    "FILE_SUFFIXES    = (\".nc\", \".nc4\")                                           # processed file extensions\n",
    "RECURSIVE_SEARCH = False                                                     # True → walk sub-folders too\n",
    "# =======================================================================\n",
    "\n",
    "def parse_time_from_filename(path: Path) -> str | None:\n",
    "    \"\"\"Return 'YYYY_MM' if six trailing digits exist, else None.\"\"\"\n",
    "    digits = ''.join(reversed([c for c in path.stem[::-1] if c.isdigit()][:6]))\n",
    "    if len(digits) == 6:\n",
    "        return f\"{digits[:4]}_{digits[4:]}\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def gather_files(root: Path, suffixes, recursive=False):\n",
    "    if recursive:\n",
    "        yield from (p for p in root.rglob(\"*\") if p.suffix in suffixes)\n",
    "    else:\n",
    "        yield from (p for p in root.iterdir() if p.suffix in suffixes)\n",
    "\n",
    "\n",
    "def extract_and_save_one(src_path: Path,\n",
    "                         variables,\n",
    "                         dst_dir: Path,\n",
    "                         overwrite=False):\n",
    "    ds = xr.open_dataset(src_path)\n",
    "    variables = [variables] if isinstance(variables, str) else list(variables)\n",
    "\n",
    "    missing = [v for v in variables if v not in ds]\n",
    "    if missing:\n",
    "        raise KeyError(f\"{src_path.name}: variable(s) not found → {missing}\")\n",
    "\n",
    "    subset = ds[variables]\n",
    "\n",
    "    time_tag = parse_time_from_filename(src_path)\n",
    "    var_part = \"_\".join(variables)\n",
    "\n",
    "    # --- NEW NAMING RULE ------------------------------------------------\n",
    "    if time_tag:                                   # date found\n",
    "        out_name = f\"{var_part}_Conc_{time_tag}.nc\"\n",
    "    else:                                          # no date → var + file name\n",
    "        out_name = f\"{var_part}_{src_path.stem}.nc\"\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "    out_path = dst_dir / out_name\n",
    "    if out_path.exists() and not overwrite:\n",
    "        raise FileExistsError(f\"{out_path} already exists (set OVERWRITE=True)\")\n",
    "\n",
    "    subset.to_netcdf(out_path, mode=\"w\", engine=\"netcdf4\")\n",
    "    print(f\"✔  {src_path.name} → {out_path.name}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    in_dir  = Path(INPUT_DIR).expanduser().resolve()\n",
    "    out_dir = Path(OUTPUT_DIR).expanduser().resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files = list(gather_files(in_dir, FILE_SUFFIXES, RECURSIVE_SEARCH))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files ending with {FILE_SUFFIXES} in {in_dir}\")\n",
    "\n",
    "    for f in files:\n",
    "        try:\n",
    "            extract_and_save_one(f, VARS_TO_EXTRACT, out_dir, overwrite=OVERWRITE)\n",
    "        except Exception as err:\n",
    "            print(f\"⚠️  Skipping {f.name}: {err}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
